{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8415ee3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e367108",
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_columns = [\n",
    "    \"TARGET\",\n",
    "    \"SK_ID_CURR\",\n",
    "    \"SK_ID_PREV\",\n",
    "    \"SK_ID_BUREAU\", \n",
    "    \"FLAG_DOCUMENT_12\",\n",
    "    \"FLAG_DOCUMENT_10\",\n",
    "    \"FLAG_DOCUMENT_2\",\n",
    "    \"FLAG_DOCUMENT_4\",\n",
    "    \"FLAG_DOCUMENT_7\",\n",
    "    \"FLAG_DOCUMENT_17\",\n",
    "    \"FLAG_DOCUMENT_21\",\n",
    "    \"FLAG_DOCUMENT_20\",\n",
    "    \"FLAG_DOCUMENT_19\",\n",
    "    \"FLAG_DOCUMENT_15\",\n",
    "    \"FLAG_DOCUMENT_14\",\n",
    "    \"FLAG_DOCUMENT_13\",\n",
    "    \"FLAG_DOCUMENT_9\",\n",
    "    \"FLAG_DOCUMENT_11\",\n",
    "    \"FLAG_DOCUMENT_18\",\n",
    "    \"FLAG_DOCUMENT_16\",\n",
    "    \"FLAG_DOCUMENT_8\",\n",
    "    \"FLAG_DOCUMENT_6\",\n",
    "    \"FLAG_DOCUMENT_5\",\n",
    "    \"FLAG_MOBIL\",\n",
    "    \"FLAG_EMP_PHONE\",\n",
    "    \"FLAG_CONT_MOBILE\",\n",
    "    \"FLAG_EMAIL\",\n",
    "    \"FLAG_WORK_PHONE\",\n",
    "    \"FLAG_PHONE\",\n",
    "    \"REG_REGION_NOT_LIVE_REGION\",\n",
    "    \"REG_REGION_NOT_WORK_REGION\",\n",
    "    \"LIVE_REGION_NOT_WORK_REGION\",\n",
    "    \"REG_CITY_NOT_LIVE_CITY\",\n",
    "    \"REG_CITY_NOT_WORK_CITY\",\n",
    "    \"LIVE_CITY_NOT_WORK_CITY\",\n",
    "    \"NAME_CONTRACT_STATUS\",\n",
    "    \"NAME_TYPE_SUITE\",\n",
    "    \"NAME_INCOME_TYPE\",\n",
    "    \"NAME_EDUCATION_TYPE\",\n",
    "    \"NAME_FAMILY_STATUS\",\n",
    "    \"NAME_HOUSING_TYPE\",\n",
    "    \"OCCUPATION_TYPE\",\n",
    "    \"ORGANIZATION_TYPE\",\n",
    "    \"WALLSMATERIAL_MODE\",\n",
    "    \"FONDKAPREMONT_MODE\",\n",
    "    \"HOUSETYPE_MODE\",\n",
    "    \"WEEKDAY_APPR_PROCESS_START\",\n",
    "    \"CODE_GENDER\",\n",
    "    \"DEF_60_CNT_SOCIAL_CIRCLE\",\n",
    "    \"DEF_30_CNT_SOCIAL_CIRCLE\",\n",
    "    \"OBS_30_CNT_SOCIAL_CIRCLE\",\n",
    "    \"OBS_60_CNT_SOCIAL_CIRCLE\",\n",
    "    \"CNT_CHILDREN\",\n",
    "    \"CNT_FAM_MEMBERS\",\n",
    "]\n",
    "\n",
    "def find_and_transform_skewed_features(\n",
    "    df, skewness_threshold=1, exclude_columns=None, shift_constant=1\n",
    "):\n",
    "    \"\"\"\n",
    "    Finds highly skewed numerical features and applies logarithmic transformation.\n",
    "\n",
    "    parameters:\n",
    "    df: data frame containing numerical features.\n",
    "    skewness_threshold: threshold for skewness coef.\n",
    "    exclude_columns: list of columns to exclude from the transformation.\n",
    "    shift_constant: this is the constant to add to features to handle zeros and negative values.\n",
    "\n",
    "    returns:\n",
    "    Dataframe with log-transformed variables.\n",
    "    \"\"\"\n",
    "    if exclude_columns is None:\n",
    "        exclude_columns = []\n",
    "\n",
    "    df_to_transform = df.drop(columns=exclude_columns, errors=\"ignore\")\n",
    "\n",
    "    skewness = df_to_transform.skew(numeric_only=True).sort_values(ascending=False)\n",
    "\n",
    "    highly_skewed_features = skewness[abs(skewness) > skewness_threshold].index.tolist()\n",
    "    \n",
    "    for feature in highly_skewed_features:\n",
    "        min_value = df_to_transform[feature].min()\n",
    "        if min_value <= 0:\n",
    "            df_to_transform[feature] = np.log1p(\n",
    "                df_to_transform[feature] - min_value + shift_constant\n",
    "            )\n",
    "        else:\n",
    "            df_to_transform[feature] = np.log1p(df_to_transform[feature])\n",
    "\n",
    "    df.update(df_to_transform)\n",
    "\n",
    "    print(f\"Log-transformed features: {highly_skewed_features}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "def feature_engineering(df):\n",
    "    df.replace(365243, np.nan, inplace=True)\n",
    "    \n",
    "    df[\"CREDIT_INCOME_RATIO\"] = df[\"AMT_CREDIT\"] / (df[\"AMT_INCOME_TOTAL\"] + 0.00001)\n",
    "    df['CREDIT_GOODS_RATIO'] = df['AMT_CREDIT'] / (df['AMT_GOODS_PRICE'] + 0.00001)\n",
    "    df['ANNUITY_INCOME_RATIO'] = df['AMT_ANNUITY'] / (df['AMT_INCOME_TOTAL'] + 0.00001)\n",
    "    df[\"CREDIT_ANNUITY_RATIO\"] = df[\"AMT_CREDIT\"] / (df[\"AMT_ANNUITY\"] + 0.00001)\n",
    "    \n",
    "    df['AGE_YEARS'] = df['DAYS_BIRTH'] / -365\n",
    "    df['EMPLOYMENT_YEARS'] = df['DAYS_EMPLOYED'] / -365\n",
    "    df['REGISTRATION_YEARS'] = df['DAYS_REGISTRATION'] / -365\n",
    "    df['ID_PUBLISH_YEARS'] = df['DAYS_ID_PUBLISH'] / -365\n",
    "\n",
    "    df['CHILDREN_RATIO'] = df['CNT_CHILDREN'] / df['CNT_FAM_MEMBERS']\n",
    "    df['INCOME_PER_FAM_MEMBER'] = df['AMT_INCOME_TOTAL'] / df['CNT_FAM_MEMBERS']\n",
    "    \n",
    "    # 4. External Sources and Aggregates\n",
    "    df['EXT_SOURCE_MEAN'] = df[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].mean(axis=1)\n",
    "    df['EXT_SOURCE_MEDIAN'] = df[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].median(axis=1)\n",
    "    \n",
    "    # 5. Flag Counts\n",
    "    df['FLAG_DOCUMENT_SUM'] = df[[f'FLAG_DOCUMENT_{i}' for i in range(2, 22)]].sum(axis=1)\n",
    "    df['FLAG_PHONE_SUM'] = df[['FLAG_MOBIL', 'FLAG_EMP_PHONE', 'FLAG_WORK_PHONE', 'FLAG_CONT_MOBILE']].sum(axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "def clean_application_train(df):\n",
    "    df = df[df[\"CODE_GENDER\"] != \"XNA\"]\n",
    "    \n",
    "    features_to_convert = [\n",
    "        \"AMT_REQ_CREDIT_BUREAU_HOUR\",\n",
    "        \"AMT_REQ_CREDIT_BUREAU_DAY\",\n",
    "        \"REGION_RATING_CLIENT\",\n",
    "        \"AMT_REQ_CREDIT_BUREAU_WEEK\",\n",
    "        \"DEF_30_CNT_SOCIAL_CIRCLE\",\n",
    "        \"DEF_60_CNT_SOCIAL_CIRCLE\",\n",
    "        \"REGION_RATING_CLIENT_W_CITY\",\n",
    "    ]\n",
    "\n",
    "    for feature in features_to_convert:\n",
    "        df[feature] = pd.to_numeric(df[feature], errors=\"coerce\")\n",
    "\n",
    "    return df\n",
    "\n",
    "def clean_previous_application(df):\n",
    "    features_to_remove = [\n",
    "        \"RATE_INTEREST_PRIMARY\",\n",
    "        \"RATE_INTEREST_PRIVILEGED\",\n",
    "        \"AMT_DOWN_PAYMENT\",\n",
    "    ]\n",
    "    df = df.drop(columns=features_to_remove, errors=\"ignore\")\n",
    "\n",
    "    df = df[df[\"AMT_ANNUITY\"] >= 0]\n",
    "\n",
    "    days_features = [\n",
    "        \"DAYS_FIRST_DRAWING\",\n",
    "        \"DAYS_FIRST_DUE\",\n",
    "        \"DAYS_LAST_DUE_1ST_VERSION\",\n",
    "        \"DAYS_LAST_DUE\",\n",
    "        \"DAYS_TERMINATION\",\n",
    "    ]\n",
    "    bin_edges = [-np.inf, -1500, -1000, -500, 0, 99999]  \n",
    "    bin_labels = [\n",
    "        \"Very Old\",\n",
    "        \"Old\",\n",
    "        \"Recent\",\n",
    "        \"Very Recent\",\n",
    "        \"Missing\",\n",
    "    ]  \n",
    "    \n",
    "    for feature in days_features:\n",
    "        df[f\"{feature}_BINNED\"] = pd.cut(\n",
    "            df[feature].replace(\n",
    "                365243, -99999\n",
    "            ), \n",
    "            bins=bin_edges,\n",
    "            labels=bin_labels,\n",
    "            include_lowest=True,\n",
    "            right=False,\n",
    "        )\n",
    "    df.drop(columns=days_features, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "def clean_installments_payments(df):\n",
    "    df[\"PAYMENT_DELAY\"] = df[\"DAYS_ENTRY_PAYMENT\"] - df[\"DAYS_INSTALMENT\"]\n",
    "\n",
    "    df = df[df[\"AMT_PAYMENT\"] >= 0]\n",
    "\n",
    "    return df\n",
    "\n",
    "def clean_bureau(df):\n",
    "    features_to_remove = [\"AMT_ANNUITY\", \"AMT_CREDIT_MAX_OVERDUE\"]\n",
    "\n",
    "    df = df.drop(columns=features_to_remove, errors=\"ignore\")\n",
    "\n",
    "    features_to_convert = [\"CNT_CREDIT_PROLONG\"]\n",
    "\n",
    "    for feature in features_to_convert:\n",
    "        df[feature] = pd.to_numeric(df[feature], errors=\"coerce\")\n",
    "\n",
    "    return df\n",
    "\n",
    "def encode_bureau_status(bureau_balance):\n",
    "    status_mapping = {\n",
    "        \"C\": 0,  # Closed\n",
    "        \"0\": 1,  # No DPD\n",
    "        \"1\": 2,  # DPD 1-30\n",
    "        \"2\": 3,  # DPD 31-60\n",
    "        \"3\": 4,  # DPD 61-90\n",
    "        \"4\": 5,  # DPD 91-120\n",
    "        \"5\": 6,  # DPD 120+ \n",
    "        \"X\": 7,  # Unknown status \n",
    "    }\n",
    "\n",
    "    bureau_balance[\"STATUS_ENCODED\"] = bureau_balance[\"STATUS\"].map(status_mapping)\n",
    "\n",
    "    return bureau_balance\n",
    "\n",
    "def aggregate_bureau_balance(bureau_balance):\n",
    "    bureau_balance_agg = (\n",
    "        bureau_balance.groupby(\"SK_ID_BUREAU\")\n",
    "        .agg(\n",
    "            MONTHS_BALANCE_MEAN=(\"MONTHS_BALANCE\", \"mean\"),\n",
    "            STATUS_MEAN=(\"STATUS_ENCODED\", \"mean\"),\n",
    "            STATUS_MAX=(\"STATUS_ENCODED\", \"max\"),\n",
    "            STATUS_MIN=(\"STATUS_ENCODED\", \"min\"),\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    bureau_balance_agg.columns = [\"SK_ID_BUREAU\"] + [\n",
    "        f\"BUREAU_BAL_{col.upper()}\" for col in bureau_balance_agg.columns[1:]\n",
    "    ]\n",
    "\n",
    "    return bureau_balance_agg\n",
    "\n",
    "def merge_bureau_and_balance(bureau_df, bureau_balance_df):\n",
    "    bureau_cleaned = clean_bureau(bureau_df)\n",
    "    \n",
    "    bureau_cleaned_transformed = find_and_transform_skewed_features(bureau_cleaned)\n",
    "\n",
    "    bureau_balance_encoded = encode_bureau_status(bureau_balance_df)\n",
    "\n",
    "    bureau_balance_agg = aggregate_bureau_balance(bureau_balance_encoded)\n",
    "\n",
    "    merged_bureau_data = bureau_cleaned.merge(\n",
    "        bureau_balance_agg, on=\"SK_ID_BUREAU\", how=\"left\"\n",
    "    )\n",
    "\n",
    "    return merged_bureau_data\n",
    "\n",
    "def merge_datasets(app_df, prev_df, inst_df, card_df, pos_cash_df, merged_bureau_data):\n",
    "    prev_app_agg = (\n",
    "        prev_df.groupby(\"SK_ID_CURR\")\n",
    "        .agg(\n",
    "            {\n",
    "                \"SK_ID_PREV\": \"nunique\",  # unique previous applications\n",
    "                \"AMT_ANNUITY\": \"mean\",  #mean of the annuity amount\n",
    "                \"AMT_APPLICATION\": \"mean\",  #mean of the application amount\n",
    "                \"AMT_CREDIT\": \"mean\",  #mean of the credit amount\n",
    "                \"AMT_GOODS_PRICE\": \"mean\",  #mean of the goods price\n",
    "                \"DAYS_FIRST_DRAWING_BINNED\": lambda x: x.mode().iloc[0]\n",
    "                if not x.mode().empty\n",
    "                else None,\n",
    "                \"DAYS_FIRST_DUE_BINNED\": lambda x: x.mode().iloc[0]\n",
    "                if not x.mode().empty\n",
    "                else None,\n",
    "                \"DAYS_LAST_DUE_1ST_VERSION_BINNED\": lambda x: x.mode().iloc[0]\n",
    "                if not x.mode().empty\n",
    "                else None,\n",
    "                \"DAYS_LAST_DUE_BINNED\": lambda x: x.mode().iloc[0]\n",
    "                if not x.mode().empty\n",
    "                else None,\n",
    "                \"DAYS_TERMINATION_BINNED\": lambda x: x.mode().iloc[0]\n",
    "                if not x.mode().empty\n",
    "                else None,\n",
    "            }\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    prev_app_agg.columns = [\"SK_ID_CURR\", \"PREV_APP_COUNT\"] + [\n",
    "        f\"PREV_{col.upper()}_{'MODE' if col.endswith('_BINNED') else 'MEAN'}\"\n",
    "        for col in prev_app_agg.columns[2:]\n",
    "    ]\n",
    "\n",
    "    inst_pay_agg = (\n",
    "        inst_df.groupby(\"SK_ID_CURR\")\n",
    "        .agg(\n",
    "            {\n",
    "                \"NUM_INSTALMENT_NUMBER\": \"nunique\", \n",
    "                \"DAYS_INSTALMENT\": \"mean\", \n",
    "                \"DAYS_ENTRY_PAYMENT\": \"mean\", \n",
    "                \"AMT_INSTALMENT\": \"mean\",\n",
    "                \"AMT_PAYMENT\": \"mean\",\n",
    "            }\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    inst_pay_agg.columns = [\"SK_ID_CURR\", \"INST_COUNT\"] + [\n",
    "        f\"INST_{col.upper()}_MEAN\" for col in inst_pay_agg.columns[2:]\n",
    "    ]\n",
    "\n",
    "    credit_card_agg = (\n",
    "        card_df.groupby(\"SK_ID_CURR\")\n",
    "        .agg(\n",
    "            {\n",
    "                \"SK_ID_PREV\": \"nunique\",\n",
    "                \"MONTHS_BALANCE\": \"mean\",\n",
    "                \"AMT_BALANCE\": \"mean\",\n",
    "                \"AMT_CREDIT_LIMIT_ACTUAL\": \"mean\",\n",
    "                \"AMT_DRAWINGS_ATM_CURRENT\": \"mean\",\n",
    "                \"AMT_DRAWINGS_CURRENT\": \"mean\",\n",
    "                \"AMT_DRAWINGS_OTHER_CURRENT\": \"mean\",\n",
    "                \"AMT_DRAWINGS_POS_CURRENT\": \"mean\",\n",
    "                \"AMT_INST_MIN_REGULARITY\": \"mean\",\n",
    "                \"AMT_PAYMENT_TOTAL_CURRENT\": \"mean\",\n",
    "                \"AMT_RECEIVABLE_PRINCIPAL\": \"mean\",\n",
    "                \"AMT_RECIVABLE\": \"mean\",\n",
    "                \"AMT_TOTAL_RECEIVABLE\": \"mean\",\n",
    "                \"CNT_DRAWINGS_ATM_CURRENT\": \"mean\",\n",
    "                \"CNT_DRAWINGS_CURRENT\": \"mean\",\n",
    "                \"CNT_DRAWINGS_OTHER_CURRENT\": \"mean\",\n",
    "                \"CNT_DRAWINGS_POS_CURRENT\": \"mean\",\n",
    "                \"CNT_INSTALMENT_MATURE_CUM\": \"mean\",\n",
    "                \"NAME_CONTRACT_STATUS\": lambda x: x.mode().iloc[0]\n",
    "                if not x.mode().empty\n",
    "                else None,\n",
    "                \"SK_DPD\": \"mean\",  \n",
    "                \"SK_DPD_DEF\": \"mean\",  \n",
    "            }\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "\n",
    "    credit_card_agg.columns = [\"SK_ID_CURR\", \"CREDIT_PREV_LOANS_COUNT\"] + [\n",
    "        f\"CREDIT_{col.upper()}_MEAN\"\n",
    "        if col != \"NAME_CONTRACT_STATUS\"\n",
    "        else f\"CREDIT_{col.upper()}_MODE\"\n",
    "        for col in credit_card_agg.columns[2:]\n",
    "    ]\n",
    "\n",
    "    pos_cash_agg = (\n",
    "        pos_cash_df.groupby(\"SK_ID_CURR\")\n",
    "        .agg(\n",
    "            {\n",
    "                \"SK_ID_PREV\": \"nunique\",\n",
    "                \"MONTHS_BALANCE\": \"mean\",\n",
    "                \"CNT_INSTALMENT\": \"mean\",\n",
    "                \"CNT_INSTALMENT_FUTURE\": \"mean\",\n",
    "                \"NAME_CONTRACT_STATUS\": lambda x: x.mode().iloc[0]\n",
    "                if not x.mode().empty\n",
    "                else None,\n",
    "                \"SK_DPD\": \"mean\",\n",
    "                \"SK_DPD_DEF\": \"mean\",\n",
    "            }\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    pos_cash_agg.columns = [\"SK_ID_CURR\", \"POS_PREV_LOANS_COUNT\"] + [\n",
    "        f\"POS_{col.upper()}_MEAN\"\n",
    "        if col != \"NAME_CONTRACT_STATUS\"\n",
    "        else f\"POS_{col.upper()}_MODE\"\n",
    "        for col in pos_cash_agg.columns[2:]\n",
    "    ]\n",
    "\n",
    "    bureau_final_agg = (\n",
    "        merged_bureau_data.groupby(\"SK_ID_CURR\")\n",
    "        .agg(\n",
    "            {\n",
    "                \"SK_ID_BUREAU\": \"nunique\",\n",
    "                \"CREDIT_ACTIVE\": lambda x: (x == \"Active\").sum(),\n",
    "                \"CREDIT_CURRENCY\": \"nunique\",\n",
    "                \"DAYS_CREDIT\": \"mean\",\n",
    "                \"CREDIT_DAY_OVERDUE\": \"mean\",\n",
    "                \"DAYS_ENDDATE_FACT\": \"mean\",\n",
    "                \"CNT_CREDIT_PROLONG\": \"sum\",\n",
    "                \"AMT_CREDIT_SUM\": \"mean\",\n",
    "                \"AMT_CREDIT_SUM_DEBT\": \"mean\",\n",
    "                \"AMT_CREDIT_SUM_LIMIT\": \"mean\",\n",
    "                \"AMT_CREDIT_SUM_OVERDUE\": \"mean\",\n",
    "                \"CREDIT_TYPE\": \"nunique\",\n",
    "                \"DAYS_CREDIT_UPDATE\": \"mean\",\n",
    "                \"BUREAU_BAL_MONTHS_BALANCE_MEAN\": \"mean\",\n",
    "                \"BUREAU_BAL_STATUS_MEAN\": \"mean\",\n",
    "                \"BUREAU_BAL_STATUS_MAX\": \"max\",\n",
    "                \"BUREAU_BAL_STATUS_MIN\": \"min\",\n",
    "            }\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    bureau_final_agg.columns = [\"SK_ID_CURR\"] + [\n",
    "        f\"BUREAU_{col.upper()}\" for col in bureau_final_agg.columns[1:]\n",
    "    ]\n",
    "\n",
    "    merged_data = app_df.merge(prev_app_agg, on=\"SK_ID_CURR\", how=\"left\")\n",
    "    merged_data = merged_data.merge(inst_pay_agg, on=\"SK_ID_CURR\", how=\"left\")\n",
    "    merged_data = merged_data.merge(credit_card_agg, on=\"SK_ID_CURR\", how=\"left\")\n",
    "    merged_data = merged_data.merge(pos_cash_agg, on=\"SK_ID_CURR\", how=\"left\")\n",
    "    merged_data = merged_data.merge(bureau_final_agg, on=\"SK_ID_CURR\", how=\"left\")\n",
    "\n",
    "    return merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aae4e7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns_to_drop=None, filter_column=None, filter_value=None):\n",
    "        self.columns_to_drop = columns_to_drop\n",
    "        self.filter_column = filter_column\n",
    "        self.filter_value = filter_value\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        if self.columns_to_drop:\n",
    "            X = X.drop(columns=self.columns_to_drop, errors=\"ignore\")\n",
    "        \n",
    "        if self.filter_column and self.filter_value is not None:\n",
    "            X = X[X[self.filter_column] != self.filter_value]\n",
    "        \n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6bcdb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_pipeline(X):\n",
    "    numerical_features = X.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "    categorical_features = X.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "\n",
    "    if \"SK_ID_CURR\" in numerical_features:\n",
    "        numerical_features.remove(\"SK_ID_CURR\")\n",
    "\n",
    "    numerical_pipeline = Pipeline(\n",
    "        steps=[\n",
    "            (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=0)),  # Impute missing values with 0\n",
    "            (\"scaler\", StandardScaler()),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    categorical_pipeline = Pipeline(\n",
    "        steps=[\n",
    "            (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"missing\")),\n",
    "            (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    preprocessor = Pipeline(\n",
    "        steps=[\n",
    "            (\"custom\", CustomTransformer(\n",
    "                columns_to_drop=[\"SK_ID_CURR\"], \n",
    "                filter_column=\"CODE_GENDER\", \n",
    "                filter_value=\"XNA\" \n",
    "            )),\n",
    "            (\"num_cat\", ColumnTransformer(\n",
    "                transformers=[\n",
    "                    (\"num\", numerical_pipeline, numerical_features),\n",
    "                    (\"cat\", categorical_pipeline, categorical_features),\n",
    "                ]\n",
    "            ))\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c94230",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_names(preprocessor, numerical_features, categorical_features):\n",
    "    numeric_feature_names = numerical_features   \n",
    "    cat_transformer = preprocessor.named_transformers_['cat']\n",
    "    categorical_feature_names = cat_transformer.get_feature_names_out(categorical_features)\n",
    "    all_feature_names = list(numeric_feature_names) + list(categorical_feature_names)\n",
    "    \n",
    "    return all_feature_names"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
